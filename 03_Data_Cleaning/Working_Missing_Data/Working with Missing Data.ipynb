{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d23b38",
   "metadata": {},
   "source": [
    "# Working with Missing Data\n",
    "\n",
    "\n",
    "![accident](http://sf.streetsblog.org/wp-content/uploads/sites/3/2013/08/IIHS-crash-photo1.jpg)\n",
    "\n",
    "Data can be missing for a variety of reasons, so how to **handle missing data without having to drop rows and columns** is a must.\n",
    "\n",
    "Using data on motor vehicle collisions released by New York City and published on the [kNYC OpenData website](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95) is our main data source.\n",
    "\n",
    "We'll work with an extract of the full data: \n",
    "\n",
    " Crashes from the year 2018. \n",
    "\n",
    "[download the data here](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95)\n",
    "\n",
    "Our data set is in a CSV called `nypd_mvc_2018.csv`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "\n",
    "`unique_key`: A unique identifier for each collision.\n",
    "\n",
    "`date, time`: Date and time of the collision.\n",
    "\n",
    "`borough`: The borough, or area of New York City, where the collision occurred.\n",
    "\n",
    "`location`: Latitude and longitude coordinates for the collision.\n",
    "\n",
    "`on_street, cross_street, off_street`: Details of the street or intersection where the collision occurred.\n",
    "\n",
    "`pedestrians_injured`: Number of pedestrians who were injured.\n",
    "\n",
    "`cyclist_injured`: Number of people traveling on a bicycle who were injured.\n",
    "\n",
    "`motorist_injured`: Number of people traveling in a vehicle who were injured.\n",
    "\n",
    "`total_injured`: Total number of people injured.\n",
    "\n",
    "`pedestrians_killed`: Number of pedestrians who were killed.\n",
    "\n",
    "`cyclist_killed`: Number of people traveling on a bicycle who were killed.\n",
    "\n",
    "`motorist_killed`: Number of people traveling in a vehicle who were killed.\n",
    "\n",
    "`total_killed`: Total number of people killed.\n",
    "\n",
    "`vehicle_1 through vehicle_5`: Type of each vehicle involved in the accident.\n",
    "\n",
    "`cause_vehicle_1 through cause_vehicle_5`: Contributing factor for each vehicle in the accident.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d3067a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>borough</th>\n",
       "      <th>location</th>\n",
       "      <th>on_street</th>\n",
       "      <th>cross_street</th>\n",
       "      <th>off_street</th>\n",
       "      <th>pedestrians_injured</th>\n",
       "      <th>cyclist_injured</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicle_1</th>\n",
       "      <th>vehicle_2</th>\n",
       "      <th>vehicle_3</th>\n",
       "      <th>vehicle_4</th>\n",
       "      <th>vehicle_5</th>\n",
       "      <th>cause_vehicle_1</th>\n",
       "      <th>cause_vehicle_2</th>\n",
       "      <th>cause_vehicle_3</th>\n",
       "      <th>cause_vehicle_4</th>\n",
       "      <th>cause_vehicle_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3869058</td>\n",
       "      <td>2018-03-23</td>\n",
       "      <td>21:40</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>(40.742832, -74.00771)</td>\n",
       "      <td>WEST 15 STREET</td>\n",
       "      <td>10 AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>PASSENGER VEHICLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Following Too Closely</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3847947</td>\n",
       "      <td>2018-02-13</td>\n",
       "      <td>14:45</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>(40.623714, -73.99314)</td>\n",
       "      <td>16 AVENUE</td>\n",
       "      <td>62 STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>SPORT UTILITY / STATION WAGON</td>\n",
       "      <td>DS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Backing Unsafely</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3914294</td>\n",
       "      <td>2018-06-04</td>\n",
       "      <td>0:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(40.591755, -73.9083)</td>\n",
       "      <td>BELT PARKWAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Station Wagon/Sport Utility Vehicle</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Following Too Closely</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        date   time    borough                location  \\\n",
       "0     3869058  2018-03-23  21:40  MANHATTAN  (40.742832, -74.00771)   \n",
       "1     3847947  2018-02-13  14:45   BROOKLYN  (40.623714, -73.99314)   \n",
       "2     3914294  2018-06-04   0:00        NaN   (40.591755, -73.9083)   \n",
       "\n",
       "                          on_street cross_street off_street  \\\n",
       "0  WEST 15 STREET                      10 AVENUE        NaN   \n",
       "1  16 AVENUE                           62 STREET        NaN   \n",
       "2  BELT PARKWAY                              NaN        NaN   \n",
       "\n",
       "   pedestrians_injured  cyclist_injured  ...  \\\n",
       "0                    0                0  ...   \n",
       "1                    0                0  ...   \n",
       "2                    0                0  ...   \n",
       "\n",
       "                             vehicle_1  vehicle_2  vehicle_3  vehicle_4  \\\n",
       "0                    PASSENGER VEHICLE        NaN        NaN        NaN   \n",
       "1        SPORT UTILITY / STATION WAGON         DS        NaN        NaN   \n",
       "2  Station Wagon/Sport Utility Vehicle      Sedan        NaN        NaN   \n",
       "\n",
       "   vehicle_5        cause_vehicle_1 cause_vehicle_2 cause_vehicle_3  \\\n",
       "0        NaN  Following Too Closely     Unspecified             NaN   \n",
       "1        NaN       Backing Unsafely     Unspecified             NaN   \n",
       "2        NaN  Following Too Closely     Unspecified             NaN   \n",
       "\n",
       "  cause_vehicle_4 cause_vehicle_5  \n",
       "0             NaN             NaN  \n",
       "1             NaN             NaN  \n",
       "2             NaN             NaN  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mvc = pd.read_csv(\"nypd_mvc_2018.csv\")\n",
    "\n",
    "mvc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57864 entries, 0 to 57863\n",
      "Data columns (total 26 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   unique_key           57864 non-null  int64  \n",
      " 1   date                 57864 non-null  object \n",
      " 2   time                 57864 non-null  object \n",
      " 3   borough              37218 non-null  object \n",
      " 4   location             53979 non-null  object \n",
      " 5   on_street            43903 non-null  object \n",
      " 6   cross_street         28615 non-null  object \n",
      " 7   off_street           13771 non-null  object \n",
      " 8   pedestrians_injured  57864 non-null  int64  \n",
      " 9   cyclist_injured      57864 non-null  int64  \n",
      " 10  motorist_injured     57864 non-null  int64  \n",
      " 11  total_injured        57863 non-null  float64\n",
      " 12  pedestrians_killed   57864 non-null  int64  \n",
      " 13  cyclist_killed       57864 non-null  int64  \n",
      " 14  motorist_killed      57864 non-null  int64  \n",
      " 15  total_killed         57859 non-null  float64\n",
      " 16  vehicle_1            57509 non-null  object \n",
      " 17  vehicle_2            45602 non-null  object \n",
      " 18  vehicle_3            3512 non-null   object \n",
      " 19  vehicle_4            706 non-null    object \n",
      " 20  vehicle_5            183 non-null    object \n",
      " 21  cause_vehicle_1      57689 non-null  object \n",
      " 22  cause_vehicle_2      49172 non-null  object \n",
      " 23  cause_vehicle_3      3730 non-null   object \n",
      " 24  cause_vehicle_4      753 non-null    object \n",
      " 25  cause_vehicle_5      193 non-null    object \n",
      "dtypes: float64(2), int64(7), object(17)\n",
      "memory usage: 11.5+ MB\n"
     ]
    }
   ],
   "source": [
    "mvc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ee092",
   "metadata": {},
   "source": [
    "### 2. Verifying the Total Columns\n",
    "\n",
    "To give us a better picture of the null values in the data, let's calculate the percentage of null values in each column. Below, we divide the number of null values in each column by the total number of values in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key                 0\n",
       "date                       0\n",
       "time                       0\n",
       "borough                20646\n",
       "location                3885\n",
       "on_street              13961\n",
       "cross_street           29249\n",
       "off_street             44093\n",
       "pedestrians_injured        0\n",
       "cyclist_injured            0\n",
       "motorist_injured           0\n",
       "total_injured              1\n",
       "pedestrians_killed         0\n",
       "cyclist_killed             0\n",
       "motorist_killed            0\n",
       "total_killed               5\n",
       "vehicle_1                355\n",
       "vehicle_2              12262\n",
       "vehicle_3              54352\n",
       "vehicle_4              57158\n",
       "vehicle_5              57681\n",
       "cause_vehicle_1          175\n",
       "cause_vehicle_2         8692\n",
       "cause_vehicle_3        54134\n",
       "cause_vehicle_4        57111\n",
       "cause_vehicle_5        57671\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts = mvc.isnull().sum()\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d226ad00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key              0.000000\n",
       "date                    0.000000\n",
       "time                    0.000000\n",
       "borough                35.680216\n",
       "location                6.714019\n",
       "on_street              24.127264\n",
       "cross_street           50.547836\n",
       "off_street             76.201092\n",
       "pedestrians_injured     0.000000\n",
       "cyclist_injured         0.000000\n",
       "motorist_injured        0.000000\n",
       "total_injured           0.001728\n",
       "pedestrians_killed      0.000000\n",
       "cyclist_killed          0.000000\n",
       "motorist_killed         0.000000\n",
       "total_killed            0.008641\n",
       "vehicle_1               0.613508\n",
       "vehicle_2              21.191069\n",
       "vehicle_3              93.930596\n",
       "vehicle_4              98.779898\n",
       "vehicle_5              99.683741\n",
       "cause_vehicle_1         0.302433\n",
       "cause_vehicle_2        15.021430\n",
       "cause_vehicle_3        93.553850\n",
       "cause_vehicle_4        98.698673\n",
       "cause_vehicle_5        99.666459\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts_pct = null_counts / mvc.shape[0] * 100\n",
    "null_counts_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe19d5",
   "metadata": {},
   "source": [
    "We'll then add both the counts and percentages to a dataframe to make them easier to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5945b2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>borough</th>\n",
       "      <th>location</th>\n",
       "      <th>on_street</th>\n",
       "      <th>cross_street</th>\n",
       "      <th>off_street</th>\n",
       "      <th>pedestrians_injured</th>\n",
       "      <th>cyclist_injured</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicle_1</th>\n",
       "      <th>vehicle_2</th>\n",
       "      <th>vehicle_3</th>\n",
       "      <th>vehicle_4</th>\n",
       "      <th>vehicle_5</th>\n",
       "      <th>cause_vehicle_1</th>\n",
       "      <th>cause_vehicle_2</th>\n",
       "      <th>cause_vehicle_3</th>\n",
       "      <th>cause_vehicle_4</th>\n",
       "      <th>cause_vehicle_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>null_counts</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20646</td>\n",
       "      <td>3885</td>\n",
       "      <td>13961</td>\n",
       "      <td>29249</td>\n",
       "      <td>44093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>355</td>\n",
       "      <td>12262</td>\n",
       "      <td>54352</td>\n",
       "      <td>57158</td>\n",
       "      <td>57681</td>\n",
       "      <td>175</td>\n",
       "      <td>8692</td>\n",
       "      <td>54134</td>\n",
       "      <td>57111</td>\n",
       "      <td>57671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>null_pct</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>93</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>93</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             unique_key  date  time  borough  location  on_street  \\\n",
       "null_counts           0     0     0    20646      3885      13961   \n",
       "null_pct              0     0     0       35         6         24   \n",
       "\n",
       "             cross_street  off_street  pedestrians_injured  cyclist_injured  \\\n",
       "null_counts         29249       44093                    0                0   \n",
       "null_pct               50          76                    0                0   \n",
       "\n",
       "             ...  vehicle_1  vehicle_2  vehicle_3  vehicle_4  vehicle_5  \\\n",
       "null_counts  ...        355      12262      54352      57158      57681   \n",
       "null_pct     ...          0         21         93         98         99   \n",
       "\n",
       "             cause_vehicle_1  cause_vehicle_2  cause_vehicle_3  \\\n",
       "null_counts              175             8692            54134   \n",
       "null_pct                   0               15               93   \n",
       "\n",
       "             cause_vehicle_4  cause_vehicle_5  \n",
       "null_counts            57111            57671  \n",
       "null_pct                  98               99  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_df = pd.DataFrame({'null_counts': null_counts, 'null_pct': null_counts_pct})\n",
    "# Rotate the dataframe so that rows become columns and vice-versa\n",
    "null_df = null_df.T.astype(int)\n",
    "\n",
    "null_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8fd889",
   "metadata": {},
   "source": [
    "About a third of the columns have no null values, with the rest ranging from less than 1% to 99%!\n",
    "\n",
    "To make things easier, let's start by looking at the group of columns that relate to people killed in collisions.\n",
    "\n",
    "We'll use list comprehension to reduce our summary dataframe to just those columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c16630be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pedestrians_killed</th>\n",
       "      <th>cyclist_killed</th>\n",
       "      <th>motorist_killed</th>\n",
       "      <th>total_killed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>null_counts</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>null_pct</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pedestrians_killed  cyclist_killed  motorist_killed  total_killed\n",
       "null_counts                   0               0                0             5\n",
       "null_pct                      0               0                0             0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "killed_cols = [col for col in mvc.columns if 'killed' in col]\n",
    "null_df[killed_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d369272f",
   "metadata": {},
   "source": [
    "Each of the individual categories have no missing values, but the `total_killed` column **has five missing values**.\n",
    "\n",
    "\n",
    " **The total number of people killed should be the sum of each of the individual categories**. \n",
    " \n",
    " We might be able to **imputation** the missing values with the sums of the individual columns for that row. \n",
    "\n",
    "\n",
    "Select just the first three columns `pedestrians_killed`, `cyclist_killed`, `motorist_killed`, and sum each row to compare the manual sum to the original total column and with this comparation create a boolean mask where equivalent values are not equal.\n",
    "\n",
    "Lastly, using the boolean mask to filter the original dataframe **to include only rows** where the manual sum and original **aren't equal**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437ad697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pedestrians_killed', 'cyclist_killed', 'motorist_killed', 'total_killed']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "killed_cols = [col for col in mvc.columns if 'killed' in col]\n",
    "killed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pedestrians_killed</th>\n",
       "      <th>cyclist_killed</th>\n",
       "      <th>motorist_killed</th>\n",
       "      <th>total_killed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57859</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57861</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57862</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57863</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57864 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pedestrians_killed  cyclist_killed  motorist_killed  total_killed\n",
       "0                       0               0                0           0.0\n",
       "1                       0               0                0           0.0\n",
       "2                       0               0                0           0.0\n",
       "3                       0               0                0           0.0\n",
       "4                       0               0                0           0.0\n",
       "...                   ...             ...              ...           ...\n",
       "57859                   0               0                0           0.0\n",
       "57860                   0               0                0           0.0\n",
       "57861                   0               0                0           0.0\n",
       "57862                   0               0                0           0.0\n",
       "57863                   0               0                0           0.0\n",
       "\n",
       "[57864 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "killed = mvc[killed_cols].copy()\n",
    "killed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the first three columns from `killed` and sum each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "57859    0\n",
       "57860    0\n",
       "57861    0\n",
       "57862    0\n",
       "57863    0\n",
       "Length: 57864, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "killed_manual_sum = killed.iloc[:,:3].sum(axis = 1)\n",
    "killed_manual_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a boolean mask that checks whether each value in `killed_manual_sum` is not equal to the values in the `total_killed` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "57859    False\n",
       "57860    False\n",
       "57861    False\n",
       "57862    False\n",
       "57863    False\n",
       "Length: 57864, dtype: bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "killed_mask = killed_manual_sum != killed['total_killed']\n",
    "killed_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `killed_mask` to filter the rows in `killed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pedestrians_killed</th>\n",
       "      <th>cyclist_killed</th>\n",
       "      <th>motorist_killed</th>\n",
       "      <th>total_killed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20163</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22046</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48719</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pedestrians_killed  cyclist_killed  motorist_killed  total_killed\n",
       "3508                    0               0                0           NaN\n",
       "20163                   0               0                0           NaN\n",
       "22046                   0               0                1           0.0\n",
       "48719                   0               0                0           NaN\n",
       "55148                   0               0                0           NaN\n",
       "55699                   0               0                0           NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "killed_non_eq = killed[killed_mask]\n",
    "killed_non_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e143f45",
   "metadata": {},
   "source": [
    "### 3. Filling and Verifying the Killed and Injured Data\n",
    "\n",
    "The `killed_non_eq` dataframe we created in the previous exercise contained six rows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e182e1",
   "metadata": {},
   "source": [
    "We can categorize these into two categories:\n",
    "\n",
    "1. Five rows where the `total_killed` **is not equal to the sum of the other columns** because the total value is missing.\n",
    "\n",
    "\n",
    "2. One row where the `total_killed` **is less than the sum of the other columns**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filling null values with the sum of the columns is a fairly good choice for our imputation\n",
    "\n",
    "We've also identified a row that has suspicious data - one that doesn't sum correctly. Once we have imputed values for all rows with missing values for `total_killed`, we'll mark this suspect row by setting its value to `NaN`.\n",
    "\n",
    "\n",
    "In order to execute this, we'll learn to use the `Series.mask()` method. `Series.mask()` is useful when you want to replace certain values in a series based off a boolean mask. The syntax for the method is:\n",
    "\n",
    "    Series.mask(bool_mask, val_to_replace)\n",
    "\n",
    "If we wanted to describe the logic of the code above, we'd say For each value in the \"fruits\" series, if the corresponding value in the \"bool\" series is true, update the value to \"Pear,\" otherwise leave the original value.\n",
    "\n",
    "In the first example above, we updated a single value, but we can also update with the matching value from a series that has identical index labels, like this `nums` series:\n",
    "\n",
    "\n",
    "![ mask_4.svg]( mask_4.svg)\n",
    "\n",
    "Let's look at how we can update the matching values in fruit with the corresponding values in nums:\n",
    "\n",
    "![ mask_5.svg]( mask_5.svg)\n",
    "\n",
    "\n",
    "If we wanted to describe the logic of the code above, we'd say For each value in the \"fruits\" series, if the corresponding value in the \"bool\" series is true, update the value to the corresponding value from \"nums,\" otherwise leave the original value.\n",
    "\n",
    "Let's look at how we'd use this technique to update the values in the `total_killed` column. First, we'll replace all null values with the equivalent values from our `killed_manual_sum` series:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ac3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "killed_null = killed['total_killed'].isnull()\n",
    "killed['total_killed'] = killed['total_killed'].mask(killed_null, killed_manual_sum)\n",
    "#killed['total_killed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144468cd",
   "metadata": {},
   "source": [
    "    0        0.0\n",
    "    1        0.0\n",
    "    2        0.0\n",
    "    3        0.0\n",
    "    4        0.0\n",
    "            ... \n",
    "    57859    0.0\n",
    "    57860    0.0\n",
    "    57861    0.0\n",
    "    57862    0.0\n",
    "    57863    0.0\n",
    "    Name: total_killed, Length: 57864, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc0e5ff",
   "metadata": {},
   "source": [
    "Next, we'll replace any values where the manual sum and the total column aren't equal with `np.nan`. This time we'll define the boolean series directly into `Series.mask()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7214822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "killed['total_killed'] = killed['total_killed'].mask(killed['total_killed'] != killed_manual_sum, np.nan)\n",
    "#killed['total_killed'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fba1c",
   "metadata": {},
   "source": [
    "    0        0.0\n",
    "    1        0.0\n",
    "    2        0.0\n",
    "    3        0.0\n",
    "    4        0.0\n",
    "            ... \n",
    "    57859    0.0\n",
    "    57860    0.0\n",
    "    57861    0.0\n",
    "    57862    0.0\n",
    "    57863    0.0\n",
    "    Name: total_killed, Length: 57864, dtype: float64\n",
    "    \n",
    "Now let's look at the values we've changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(killed[killed_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d910406",
   "metadata": {},
   "source": [
    "We've gone from five null values to one, and flagged some suspicious data. Let's do the same for the injured columns.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "We included the code to clean the `killed` columns. In addition, we've created an `injured` dataframe with just the injured columns and `injured_manual_sum`, a series manually summing the three individual injured columns.\n",
    "\n",
    "1. Use `Series.mask()` to replace any null values from the `total_injured` column with their equivalents from the `injured_manual_sum` series.\n",
    "\n",
    "2. Use `Series.mask()` to replace any numbers from `total_injured` that aren't equal to their equivalents in `injured_manual_sum` with `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ca88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# fix the killed values\n",
    "killed['total_killed'] = killed['total_killed'].mask(killed['total_killed'].isnull(), killed_manual_sum)\n",
    "killed['total_killed'] = killed['total_killed'].mask(killed['total_killed'] != killed_manual_sum, np.nan)\n",
    "\n",
    "# Create an injured dataframe and manually sum values\n",
    "injured = mvc[[col for col in mvc.columns if 'injured' in col]].copy()\n",
    "injured_manual_sum = injured.iloc[:,:3].sum(axis=1)\n",
    "\n",
    "injured_null = injured['total_injured'].isnull()\n",
    "injured['total_injured'] = injured['total_injured'].mask(injured_null,injured_manual_sum )\n",
    "\n",
    "injured['total_injured'] = injured['total_injured'].mask(injured['total_injured'] != injured_manual_sum, np.nan)\n",
    "#injured['total_injured'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa09754",
   "metadata": {},
   "source": [
    "    0        0.0\n",
    "    1        0.0\n",
    "    2        1.0\n",
    "    3        0.0\n",
    "    4        0.0\n",
    "            ... \n",
    "    57859    3.0\n",
    "    57860    0.0\n",
    "    57861    1.0\n",
    "    57862    0.0\n",
    "    57863    0.0\n",
    "    Name: total_injured, Length: 57864, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f1ba2",
   "metadata": {},
   "source": [
    "### 4. Assigning the Corrected Data Back to the Main Dataframe\n",
    "\n",
    "Let's summarize the count of null values before and after our changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d6c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'injured': [\n",
    "        mvc['total_injured'].isnull().sum(),\n",
    "        injured['total_injured'].isnull().sum()\n",
    "    ],\n",
    "    'killed': [\n",
    "        mvc['total_killed'].isnull().sum(),\n",
    "        killed['total_killed'].isnull().sum()\n",
    "    ]\n",
    "}\n",
    "print(pd.DataFrame(summary, index=['before','after']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1397ea",
   "metadata": {},
   "source": [
    "For the `total_killed` column, the number of values has gone down from 5 to 1. For the `total_injured` column, the number of values has actually gone up â€” from 1 to 21. This might sound like we've done the opposite of what we set out to do, but what we've actually done is fill all the null values and identify values that have suspect data. This will make any analysis we do on this data more accurate in the long run.\n",
    "\n",
    "Let's assign the values from the `killed` and `injured` dataframe back to the main `mvc` dataframe:\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Assign the `total_injured` column from the `injured` dataframe to the same column in the `mvc` dataframe.\n",
    "\n",
    "2. Assign the `total_killed` column from the `killed` dataframe to the same column in the `mvc` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e0669",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvc['total_injured'] = injured['total_injured']\n",
    "#mvc['total_injured']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311afbaa",
   "metadata": {},
   "source": [
    "    0        0.0\n",
    "    1        0.0\n",
    "    2        1.0\n",
    "    3        0.0\n",
    "    4        0.0\n",
    "            ... \n",
    "    57859    3.0\n",
    "    57860    0.0\n",
    "    57861    1.0\n",
    "    57862    0.0\n",
    "    57863    0.0\n",
    "    Name: total_injured, Length: 57864, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvc['total_injured'] = injured['total_injured']\n",
    "#mvc['total_killed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e408f40d",
   "metadata": {},
   "source": [
    "    0        0.0\n",
    "    1        0.0\n",
    "    2        0.0\n",
    "    3        0.0\n",
    "    4        0.0\n",
    "            ... \n",
    "    57859    0.0\n",
    "    57860    0.0\n",
    "    57861    0.0\n",
    "    57862    0.0\n",
    "    57863    0.0\n",
    "    Name: total_killed, Length: 57864, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b583ca",
   "metadata": {},
   "source": [
    "### 5. Visualizing Missing Data with Plots\n",
    "\n",
    "Earlier, we used a table of numbers to understand the number of missing values in our dataframe. A different approach we can take is to use a plot to visualize the missing values. The function below uses `seaborn.heatmap()` to represent null values as light squares and non-null values as dark squares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_null_matrix(df, figsize=(18,15)):\n",
    "    # initiate the figure\n",
    "    plt.figure(figsize=figsize)\n",
    "    # create a boolean dataframe based on whether values are null\n",
    "    df_null = df.isnull()\n",
    "    # create a heatmap of the boolean dataframe\n",
    "    sns.heatmap(~df_null, cbar=False, yticklabels=False)\n",
    "    plt.xticks(rotation=90, size='x-large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea480615",
   "metadata": {},
   "source": [
    "Let's look at how the function works by using it to plot just the first row of our `mvc` dataframe. We'll display the first row as a table immediately below so it's easy to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_null_matrix(mvc.head(1), figsize=(18,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mvc.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c3960",
   "metadata": {},
   "source": [
    "Each value is represented by a dark square, and each missing value is represented by a light square.\n",
    "\n",
    "Let's look at what a plot matrix looks like for the whole dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c9bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_null_matrix(mvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a349c27",
   "metadata": {},
   "source": [
    "We can make some immediate interpretations about our dataframe:\n",
    "\n",
    "- The first three columns have few to no missing values.\n",
    "\n",
    "- The next five columns have missing values scattered throughout, with each column seeming to have its own density of missing values.\n",
    "\n",
    "- The next eight columns are the `injury` and `killed` columns we just cleaned, and only have a few missing values.\n",
    "\n",
    "- The last 10 columns seem to break into two groups of five, with each group of five having similar patterns of null/non-null values.\n",
    "\n",
    "Let's examine the pattern in the last 10 columns a little more closely. We can calculate the relationship between two sets of columns, known as **correlation**. To calculate this we use the `dataframe.corr()` method (You'll learn more about **correlation** in a later course). Here's what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3911b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_missing_vals = mvc.columns[mvc.isnull().sum() > 0]\n",
    "missing_corr = mvc[cols_with_missing_vals].isnull().corr()\n",
    "print(missing_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07447ed",
   "metadata": {},
   "source": [
    "Each value is between  âˆ’1 and  1 , and represents the relationship between two columns. A number close to âˆ’1 or 1 represents a strong relationship, where a number in the middle (close to 0 ) represents a weak relationship.\n",
    "\n",
    "If you look closely, you can see a diagonal line of  1s going from top left to bottom right. These values represent each columns relationship with itself, which of course is a perfect relationship. The values on the top/right of this \"line of \n",
    "1s\" mirror the values on the bottom/left of this line: The table actually repeats every value twice!\n",
    "\n",
    "Correlation tables can be hard to interpret. We can convert our table into a plot which will make this a lot easier. Let's see what this plot looks like:\n",
    "\n",
    "![ correlations_df.png]( correlations_df.png)\n",
    "\n",
    "\n",
    "In our correlation plot:\n",
    "\n",
    "The \"line of 1s\" and the repeated values are removed so that it's not visually overwhelming.Values very close to 0, where there is little to no relationship, aren't labeled.\n",
    "\n",
    "Values close to 1 are dark blue and values close to âˆ’1\n",
    " are dark red â€” the depth of color represents the strength of the relationship.\n",
    "We provided a helper function to create correlation plots. Let's create a correlation plot of just those last 10 columns to see if we can more closely identify the pattern we saw earlier in the matrix plot.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "We created a function, `plot_null_correlations()`, which will plot correlations between null values in a dataframe.\n",
    "\n",
    "Use list comprehension to produce a list of column names containing the substring `'vehicle'`.\n",
    "Use the list of column names to select only those columns from the `mvc` dataframe. Pass the result to the `plot_null_correlations()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0ad9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_null_correlations(df):\n",
    "    # create a correlation matrix only for columns with at least\n",
    "    # one missing value\n",
    "    cols_with_missing_vals = df.columns[df.isnull().sum() > 0]\n",
    "    missing_corr = df[cols_with_missing_vals].isnull().corr()\n",
    "    \n",
    "    # create a mask to avoid repeated values and make\n",
    "    # the plot easier to read\n",
    "    missing_corr = missing_corr.iloc[1:, :-1]\n",
    "    mask = np.triu(np.ones_like(missing_corr), k=1)\n",
    "    \n",
    "    # plot a heatmap of the values\n",
    "    plt.figure(figsize=(20,14))\n",
    "    ax = sns.heatmap(missing_corr, vmin=-1, vmax=1, cbar=False,\n",
    "                     cmap='RdBu', mask=mask, annot=True)\n",
    "    \n",
    "    # format the text in the plot to make it easier to read\n",
    "    for text in ax.texts:\n",
    "        t = float(text.get_text())\n",
    "        if -0.05 < t < 0.01:\n",
    "            text.set_text('')\n",
    "        else:\n",
    "            text.set_text(round(t, 2))\n",
    "        text.set_fontsize('x-large')\n",
    "    plt.xticks(rotation=90, size='x-large')\n",
    "    plt.yticks(rotation=0, size='x-large')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "vehicles_cols = [col for col in mvc.columns if 'vehicle' in col]\n",
    "\n",
    "vehicles = mvc[vehicles_cols]\n",
    "\n",
    "plot_null_correlations(vehicles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5469d",
   "metadata": {},
   "source": [
    "### 6. Analyzing Correlations in Missing Data\n",
    "\n",
    "![ correlations_vehicles_1.png]( correlations_vehicles_1.png)\n",
    "\n",
    "\n",
    "We outlined a diagonal strip of five squares in green that have a higher correlation than the rest. The pairs of column names that make up these five correlations are:\n",
    "\n",
    "1. `vehicle_1` and `cause_vehicle_1`\n",
    "2. `vehicle_2` and `cause_vehicle_2`\n",
    "3. `vehicle_3` and `cause_vehicle_3`\n",
    "4. `vehicle_4` and `cause_vehicle_4`\n",
    "5. `vehicle_5` and `cause_vehicle_5`\n",
    "\n",
    "If you think about it, this makes sense. When a vehicle is in an accident, there is likely to be a cause, and vice-versa.\n",
    "\n",
    "Let's explore the variations in missing values from these five pairs of columns. We'll create a dataframe that counts, for each pair:\n",
    "\n",
    "- The number of values where the vehicle is missing when the cause is not missing.\n",
    "\n",
    "- The number of values where the cause is missing when the vehicle is not missing.\n",
    "\n",
    "The final structure of our dataframe will look like this:\n",
    "\n",
    "\n",
    "|\t|   |v_number|\tvehicle_missing\t|use_missing|\n",
    "|:--|:--|:--     |:--               |:--        |\n",
    "|0\t|   |1       |\t[count]         |\t[count] |\n",
    "|1\t|   |2       |\t[count]         |\t[count] |\n",
    "|2\t|   |3       |\t[count]         |\t[count] |\n",
    "|3\t|   |4       |\t[count]         |\t[count] |\n",
    "|4\t|   |5       |\t[count]         |\t[count] |\n",
    "|5\t|   |6       |\t[count]         |\t[count] |\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "We provided the start of the loop you are going to build, including code that generates each column name as strings: `v_col` and `c_col`\n",
    "\n",
    "1. Uncomment the commented lines (you might want to use this keyboard shortcut).\n",
    "2. Add code to the body of the loop that will:\n",
    "\n",
    "- Count the number of rows where the `v_col` column is null and the `c_col` column is not null. Assign the result to `v_null`.\n",
    "\n",
    "- Count the number of rows where the `c_col` column is null and the `v_col` column is not null. Assign the result to `c_null`.\n",
    "\n",
    "- Append an item to the `vc_null_data` list. The item should be a list containing, in order: `v`, `v_null`, `c_null`.\n",
    "\n",
    "3. Outside the loop, create a dataframe using the `vc_null_data` list of lists.\n",
    "\n",
    "- Use the columns parameter and the `col_labels` list to set the column names of the dataframe.\n",
    "\n",
    "- Assign the dataframe to `vc_null_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e52de",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labels = ['v_number', 'vehicle_missing', 'cause_missing']\n",
    "\n",
    "vc_null_data = []\n",
    "\n",
    "for v in range(1,6):\n",
    "    v_col = 'vehicle_{}'.format(v)\n",
    "    c_col = 'cause_vehicle_{}'.format(v)\n",
    "    \n",
    "    v_null = (mvc[v_col].isnull() & mvc[c_col].notnull()).sum()\n",
    "    c_null = (mvc[c_col].isnull() & mvc[v_col].notnull()).sum()\n",
    "    \n",
    "    vc_null_data.append([v, v_null, c_null])\n",
    "\n",
    "vc_null_df = pd.DataFrame(vc_null_data, columns=col_labels)\n",
    "vc_null_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f0382e",
   "metadata": {},
   "source": [
    "### 7. Finding the Most Common Values Across Multiple Columns\n",
    "\n",
    "The analysis we did on the previous screen indicates that there are roughly 4,500 missing values across the 10 columns. The easiest option for handling these would be to drop the rows with missing values. This would mean losing almost 10% of the total data, which is something we ideally want to avoid.\n",
    "\n",
    "A better option is to impute the data, like we did earlier. Because the data in these columns is text data, we can't perform a numeric calculation to impute missing data like we did with the injuries and killed columns.\n",
    "\n",
    "One common option when imputing is to use the most common value to fill in data. Let's look at the common values across these columns and see if we can use that to make a decision.\n",
    "\n",
    "We've previously used the Series.value_counts() method to find the most common values in a single column. In this case, we want to find the most common values across multiple columns. In order to do this, we first need to convert our dataframe of multiple columns into one single column, and then we can use Series.value_counts() to count the items.\n",
    "\n",
    "To convert a dataframe to a single column of values, we use the DataFrame.stack() method, which stacks a dataframe object into a Series object. Let's look at a diagram of how this works. We'll start with a simple dataframe with three columns containing words:\n",
    "\n",
    "\n",
    "![stack_count_1.svg](stack_count_1.svg)\n",
    "\n",
    "When we use `DataFrame.stack()`, the values become a series object, with the values from each row \"stacked\" on top of each other:\n",
    "\n",
    "![stack_count_2.svg](stack_count_2.svg)\n",
    "\n",
    "This series object actually has two row indexes. The first index is the original row index, and the second contains the columns that correspond to the value.\n",
    "\n",
    "Once we have this stacked series, we can just use `Series.value_counts()` to count the values:\n",
    "\n",
    "![stack_count_3.svg](stack_count_3.svg)\n",
    "\n",
    "Let's use this technique to count the most common values for the cause set of columns. We'll start by selecting only the columns containing the substring `cause`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_cols = [c for c in mvc.columns if \"cause_\" in c]\n",
    "cause = mvc[cause_cols]\n",
    "print(cause.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc558a",
   "metadata": {},
   "source": [
    "Next, we'll stack the values into a single series object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c8993",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_1d = cause.stack()\n",
    "print(cause_1d.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17280d1b",
   "metadata": {},
   "source": [
    "You may notice that the stacked version omits null values - this is fine, as we're just interested in the most common non-null values.\n",
    "\n",
    "Finally, we count the values in the series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75472ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_counts = cause_1d.value_counts()\n",
    "top10_causes = cause_counts.head(10)\n",
    "print(top10_causes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da78c1",
   "metadata": {},
   "source": [
    "The most common non-null value for the cause columns is Unspecified, which presumably indicates that the officer reporting the collision was unable to determine the cause for that vehicle.\n",
    "\n",
    "Let's use the same technique to identify the most common non-null value for the vehicle columns.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "We provided a list comprehension that identifies columns starting with the substring `vehicle`.\n",
    "\n",
    "1. Create a dataframe containing only the columns from `mvc`, identified by the list comprehension `v_cols`.\n",
    "\n",
    "2. Use `DataFrame.stack()` to stack the values from the dataframe into a single series object.\n",
    "\n",
    "3. Use `Series.value_counts()` to count the unique values from the stacked series. Assign the first 10 values to `top10_vehicles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cols = [c for c in mvc.columns if c.startswith(\"vehicle\")]\n",
    "\n",
    "vehicles = mvc[v_cols]\n",
    "vehicles_1d = vehicles.stack()\n",
    "vehicles_counts = vehicles_1d.value_counts()\n",
    "top10_vehicles = vehicles_counts.head(10)\n",
    "top10_vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb0af7",
   "metadata": {},
   "source": [
    "### 8. Filling Unknown Values with a Placeholder\n",
    "\n",
    "Let's look at the values analysis we completed on the previous screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top10_vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ade3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(top_10_causes) la variable no estÃ¡ definida??? esto es lo que sale en el ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82fe43d",
   "metadata": {},
   "source": [
    "    Unspecified                       57481\n",
    "    Driver Inattention/Distraction    17650\n",
    "    Following Too Closely              6567\n",
    "    Failure to Yield Right-of-Way      4566\n",
    "    Passing or Lane Usage Improper     3260\n",
    "    Passing Too Closely                3045\n",
    "    Backing Unsafely                   3001\n",
    "    Other Vehicular                    2523\n",
    "    Unsafe Lane Changing               2372\n",
    "    Turning Improperly                 1590\n",
    "    dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61729bbd",
   "metadata": {},
   "source": [
    "The top \"cause\" is an \"Unspecified\" placeholder. This is useful instead of a null value as it makes the distinction between a value that is missing because there were only a certain number of vehicles in the collision versus one that is because the contributing cause for a particular vehicle is unknown.\n",
    "\n",
    "The vehicles columns don't have an equivalent, but we can still use the same technique. Here's the logic we'll need to do for each pair of vehicle/cause columns:\n",
    "\n",
    "1. For values where the vehicle is null and the cause is non-null, set the vehicle to Unspecified.\n",
    "\n",
    "2. For values where the cause is null and the vehicle is not-null, set the cause to Unspecified.\n",
    "\n",
    "We can use `Series.mask()` to replace the values, just like we did earlier in the lesson. Let's look at code to perform this for the vehicle_1 and vehicle_cause_1 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a mask for each column\n",
    "v_missing_mask = mvc['vehicle_1'].isnull() & mvc['cause_vehicle_1'].notnull()\n",
    "c_missing_mask = mvc['cause_vehicle_1'].isnull() & mvc['vehicle_1'].notnull()\n",
    "\n",
    "# replace the values matching the mask for each column\n",
    "mvc['vehicle_1'] =  mvc['vehicle_1'].mask(v_missing_mask, \"Unspecified\")\n",
    "mvc['cause_vehicle_1'] =  mvc['cause_vehicle_1'].mask(c_missing_mask, \"Unspecified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dc297b",
   "metadata": {},
   "source": [
    "Now let's use a loop to fill in these values across all columns. We've created a helper function summarize_missing() which contains the logic we used earlier to count missing values across the pairs of columns. Below is a quick demonstration on how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b744744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_missing():\n",
    "    v_missing_data = []\n",
    "\n",
    "    for v in range(1,6):\n",
    "        v_col = 'vehicle_{}'.format(v)\n",
    "        c_col = 'cause_vehicle_{}'.format(v)\n",
    "\n",
    "        v_missing = (mvc[v_col].isnull() & mvc[c_col].notnull()).sum()\n",
    "        c_missing = (mvc[c_col].isnull() & mvc[v_col].notnull()).sum()\n",
    "\n",
    "        v_missing_data.append([v, v_missing, c_missing])\n",
    "\n",
    "    col_labels = columns=[\"vehicle_number\", \"vehicle_missing\", \"cause_missing\"]\n",
    "    return pd.DataFrame(v_missing_data, columns=col_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summarize_missing())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a73b74",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "In addition to the helper function, we provided the start of the loop you are going to build, including code that generates each column name as a string.\n",
    "\n",
    "1. Uncomment the commented lines (you might want to use this keyboard shortcut).\n",
    "\n",
    "2. Add code to the body of the loop that:\n",
    "\n",
    "- Creates a boolean mask for values where the vehicle column is null and the cause column is non-null.\n",
    "\n",
    "- Creates a boolean mask for values where the cause column is null and the vehicle column is non-null.\n",
    "\n",
    "- Uses the first boolean mask to fill matching values from the vehicle column with the string `Unspecified`.\n",
    "\n",
    "- Uses the second boolean mask to fill matching values from the cause column with the string `Unspecified`.\n",
    "\n",
    "3. Outside the loop, use the `summarize_missing()` function to check that you have removed all matching values. Assign the result to `summary_after`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0939d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_missing():\n",
    "    v_missing_data = []\n",
    "\n",
    "    for v in range(1,6):\n",
    "        v_col = 'vehicle_{}'.format(v)\n",
    "        c_col = 'cause_vehicle_{}'.format(v)\n",
    "\n",
    "        v_missing = (mvc[v_col].isnull() & mvc[c_col].notnull()).sum()\n",
    "        c_missing = (mvc[c_col].isnull() & mvc[v_col].notnull()).sum()\n",
    "\n",
    "        v_missing_data.append([v, v_missing, c_missing])\n",
    "\n",
    "    col_labels = columns=[\"vehicle_number\", \"vehicle_missing\", \"cause_missing\"]\n",
    "    return pd.DataFrame(v_missing_data, columns=col_labels)\n",
    "\n",
    "summary_before = summarize_missing()\n",
    "\n",
    "for v in range(1,6):\n",
    "    v_col = 'vehicle_{}'.format(v)\n",
    "    c_col = 'cause_vehicle_{}'.format(v)\n",
    "    \n",
    "    v_missing_mask = mvc[v_col].isnull() & mvc[c_col].notnull()\n",
    "    c_missing_mask = mvc[c_col].isnull() & mvc[v_col].notnull()\n",
    "\n",
    "    mvc[v_col] = mvc[v_col].mask(v_missing_mask, \"Unspecified\")\n",
    "    mvc[c_col] = mvc[c_col].mask(c_missing_mask, \"Unspecified\")\n",
    "\n",
    "summary_after = summarize_missing()\n",
    "summary_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0c69c2",
   "metadata": {},
   "source": [
    "### 9. Missing Data in the \"Location\" Columns\n",
    "\n",
    "Let's view the work we've done across the past few screens by looking at the null correlation plot for the last 10 columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8ff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "veh_cols = [c for c in mvc.columns if 'vehicle' in c]\n",
    "plot_null_correlations(mvc[veh_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e947a83",
   "metadata": {},
   "source": [
    "You can see the perfect correlation between each pair of vehicle/cause columns represented by \n",
    "1.0\n",
    " in each square, which means that there is a perfect relationship between the five pairs of vehicle/cause columns.\n",
    "\n",
    "Let's now turn our focus to the final set of columns that contain missing values â€” the columns that relate to the location of the accident. We'll start by looking at the first few rows to refamiliarize ourselves with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339daf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_cols = ['borough', 'location', 'on_street', 'off_street', 'cross_street']\n",
    "location_data = mvc[loc_cols]\n",
    "print(location_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a07a772",
   "metadata": {},
   "source": [
    "Next, let's look at counts of the null values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f726c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(location_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8f9af",
   "metadata": {},
   "source": [
    "These columns have a lot of missing values! Keep in mind that all of these five columns represent the same thing â€” the location of the collision. We can potentially use the non-null values to impute some of the null values.\n",
    "\n",
    "To see where we might be able to do this, let's look for correlations between the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_null_correlations(location_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a231efd",
   "metadata": {},
   "source": [
    "None of these columns have strong correlations except for `off_street` and `on_street` which have a near perfect negative correlation. That means for almost every row that has a null value in one column, the other has a non-null value and vice-versa.\n",
    "\n",
    "The final way we'll look at the null values in these columns is to plot a null matrix, but we'll sort the data first. This will gather some of the null and non-null values together and make patterns more obvious:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e8aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_location_data = location_data.sort_values(loc_cols)\n",
    "plot_null_matrix(sorted_location_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e3892",
   "metadata": {},
   "source": [
    "Let's make some observations about the missing values across these columns:\n",
    "\n",
    "1. About two-thirds of rows have non-null values for `borough`, but of those values that are missing, most have non-null values for `location` and one or more of the street name columns.\n",
    "\n",
    "2. Less than one-tenth of rows have missing values in the `location` column, but most of these have non-null values in one or more of the street name columns.\n",
    "\n",
    "3. Most rows have a non-null value for either `on_street` or `off_street`, and some also have a value for `cross_street`.\n",
    "\n",
    "Combined, this means that we will be able to impute a lot of the missing values by using the other columns in each row. To do this, we can use geolocation APIs that take either an address or location coordinates, and return information about that location.\n",
    "\n",
    "Because the focus of this lesson is working with missing data, we have pre-prepared supplemental data using APIs. On the next screen, we'll learn more about how that data was prepared and then use it to fill in missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c3809",
   "metadata": {},
   "source": [
    "### 10. Imputing Location Data\n",
    "\n",
    "We prepared the supplemental data using the [GeoPy](https://geopy.readthedocs.io/en/latest/) package, which makes working with Geocoding APIs like the Google Maps API easier. Here's the strategy we used to prepare the supplemental data:\n",
    "\n",
    "- For rows with `location` values but missing values in either `borough` or the street name columns, we used geocoding APIs to look up the location coordinates to find the missing data.\n",
    "\n",
    "- For rows with values in the street name columns missing `borough` and/or `location` data, we used geocoding APIs to look up the address to find the missing data.\n",
    "\n",
    "You can learn more about working with APIs in our APIs and Web Scraping course.\n",
    "\n",
    "The supplemental data is in a CSV called `supplemental_data.csv`, let's read this into a pandas dataframe and familiarize ourself with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782cdbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_data = pd.read_csv('supplemental_data.csv')\n",
    "sup_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eab82d",
   "metadata": {},
   "source": [
    "The supplemental data has five columns from our original data set â€” the `unique_key` that identifies each collision, and four of the five location columns. The `cross_street` column is not included because the geocoding APIs we used don't include data on the nearest cross street to any single location.\n",
    "\n",
    "Let's take a look at a null matrix for the supplemental data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_null_matrix(sup_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea956b6",
   "metadata": {},
   "source": [
    "Apart from the `unique_key` column, you'll notice that there are a lot more missing values than our main data set. This makes sense, as we didn't prepare supplemental data where the original data set had non-null values.\n",
    "\n",
    "If the `unique_key` column in both the original and supplemental data has the same values in the same order, we'll be able to use `Series.mask()` to add our supplemental data to our original data. We can check this using the Series.equals() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21718579",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvc_keys = mvc['unique_key']\n",
    "sup_keys = sup_data['unique_key']\n",
    "\n",
    "is_equal = mvc_keys.equals(sup_keys)\n",
    "print(is_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9525c1",
   "metadata": {},
   "source": [
    "Now that we've verified the data, it's time to use it to impute missing values.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. We read the supplemental data into a dataframe called sup_data. Additionally, we provided a list of the location columns, `location_cols`, and calculated the number of null values in these columns.\n",
    "\n",
    "2. Loop over the column names in `location_cols`. In each iteration of the loop, use `Series.mask()` to replace values in the column in the `mvc` dataframe:\n",
    "\n",
    "- The mask should represent whether the values in column in the `mvc` has a null value or not.\n",
    "\n",
    "- Where the mask is true, the value should be replaced with the equivalent value in `sup_data`.\n",
    "\n",
    "2. Calculate the number of null values across the `location_cols` columns in `mvc` after you adding the supplemental data. Assign the result to `null_after`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd946f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_data = pd.read_csv('supplemental_data.csv')\n",
    "\n",
    "location_cols = ['location', 'on_street', 'off_street', 'borough']\n",
    "null_before = mvc[location_cols].isnull().sum()\n",
    "\n",
    "for col in location_cols:\n",
    "    mvc[col] = mvc[col].mask(mvc[col].isnull(), sup_data[col])\n",
    "\n",
    "null_after = mvc[location_cols].isnull().sum()\n",
    "null_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d1a5b",
   "metadata": {},
   "source": [
    "### 11. Next Steps\n",
    "\n",
    "In this lesson, we've imputed thousands of values to reduce the number of missing values across our data set. Let's look at a summary of the null values before and after our data cleaning:\n",
    "\n",
    "\n",
    "||original|\tfinal|\tpct_change|\n",
    "|:--         |        |         |            |\n",
    "|borough|\t20646|\t232      |\t-0.989|\n",
    "|location|\t3885|\t77       |\t-0.980|\n",
    "|on_street|\t13961|\t13734    |\t-0.016|\n",
    "|cross_street|\t29249|\t29249|\t0.000|\n",
    "|off_street|\t44093|\t36131|\t-0.181|\n",
    "|total_injured|\t1|\t21|\t20.000|\n",
    "|total_killed|\t5|\t1|\t-0.800|\n",
    "|vehicle_1|\t355|\t151|\t-0.575|\n",
    "|vehicle_2|\t12262|\t8469|\t-0.309|\n",
    "|vehicle_3|\t54352|\t54110|\t-0.004|\n",
    "|vehicle_4|\t57158|\t57108|\t-0.001|\n",
    "|vehicle_5|\t57681|\t57671|\t-0.000|\n",
    "|cause_vehicle_1|\t175|\t151\t|-0.137|\n",
    "|cause_vehicle_2|\t8692|\t8469|\t-0.026|\n",
    "|cause_vehicle_3|\t54134|\t54110|\t-0.000|\n",
    "|cause_vehicle_4|\t57111|\t57108|\t-0.000|\n",
    "|cause_vehicle_5|\t57671|\t57671|\t0.000|\n",
    "\n",
    "\n",
    "\n",
    "If you'd like to continue working with this data, you can:\n",
    "\n",
    "- Drop the rows that had suspect values for `injured` and `killed` totals.\n",
    "\n",
    "- Clean the values in the `vehicle_1` through `vehicle_5` columns by analyzing the different values and merging duplicates and near-duplicates.\n",
    "\n",
    "- Analyze whether collisions are more likely in certain locations, at certain times, or for certain vehicle types."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
